{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "u-net encoder clf.ipyb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19AOWsmZSJmPYcp15qIBIzLMqKo-JCnE5",
      "authorship_tag": "ABX9TyPFI9xVngElxkoNtCAVZppd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hyun-park/training/blob/master/u_net_encoder_clf_ipyb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1aIscQYpaIC"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "import albumentations.pytorch\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvWNBEWBpdSJ"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "lr = 0.001\n",
        "momentum = 0.99\n",
        "\n",
        "batch_size = 32\n",
        "test_batch_size = 3\n",
        "\n",
        "epochs = 200\n",
        "log_interval = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfHGXc8Tc8JO"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3VRucOfpfro"
      },
      "source": [
        "path = '/content/drive/MyDrive/oxford_pet'\n",
        "image_path =os.path.join(path+'/images')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_JAsI0Opfuo"
      },
      "source": [
        "image_path_list = glob(image_path+'/*.jpg')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GxSzCpZrMCu"
      },
      "source": [
        "label_list = list()\n",
        "for path in image_path_list:\n",
        "    label_list.append(re.sub('_\\d+','',path).split('/')[-1].split('.')[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VzjVgBXQ7HE",
        "outputId": "6a8a9050-ada2-4319-fc69-c447bf2b8672"
      },
      "source": [
        "class_list = set()\n",
        "for path in image_path_list:\n",
        "  file_name = os.path.splitext(path)[0]\n",
        "  class_name = re.sub('_\\d+','',file_name).split('/')[-1]\n",
        "  class_list.add(class_name)\n",
        "class_list = sorted(list(class_list))\n",
        "\n",
        "class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n",
        "class2idx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abyssinian': 0,\n",
              " 'Bengal': 1,\n",
              " 'Birman': 2,\n",
              " 'Bombay': 3,\n",
              " 'British_Shorthair': 4,\n",
              " 'Egyptian_Mau': 5,\n",
              " 'Maine_Coon': 6,\n",
              " 'Persian': 7,\n",
              " 'Ragdoll': 8,\n",
              " 'Russian_Blue': 9,\n",
              " 'Siamese': 10,\n",
              " 'Sphynx': 11,\n",
              " 'american_bulldog': 12,\n",
              " 'american_pit_bull_terrier': 13,\n",
              " 'basset_hound': 14,\n",
              " 'beagle': 15,\n",
              " 'boxer': 16,\n",
              " 'chihuahua': 17,\n",
              " 'english_cocker_spaniel': 18,\n",
              " 'english_setter': 19,\n",
              " 'german_shorthaired': 20,\n",
              " 'great_pyrenees': 21,\n",
              " 'havanese': 22,\n",
              " 'japanese_chin': 23,\n",
              " 'keeshond': 24,\n",
              " 'leonberger': 25,\n",
              " 'miniature_pinscher': 26,\n",
              " 'newfoundland': 27,\n",
              " 'pomeranian': 28,\n",
              " 'pug': 29,\n",
              " 'saint_bernard': 30,\n",
              " 'samoyed': 31,\n",
              " 'scottish_terrier': 32,\n",
              " 'shiba_inu': 33,\n",
              " 'staffordshire_bull_terrier': 34,\n",
              " 'wheaten_terrier': 35,\n",
              " 'yorkshire_terrier': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tMgJ-X-pjIt"
      },
      "source": [
        "df= pd.DataFrame(list(zip(image_path_list,label_list)),index = range(len(image_path_list)),columns = ['image_path','label'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSB1vHOuSIzN"
      },
      "source": [
        "binary_idx = list()\n",
        "for i in range(7387):\n",
        "  label_idx = class2idx[df.iloc[i,1]]\n",
        "  if label_idx <12:\n",
        "    binary_idx.append('0')\n",
        "  else:\n",
        "    binary_idx.append('1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOsMHZb6Tp78",
        "outputId": "58b35edb-8c48-4309-abd0-b39fe97db4d8"
      },
      "source": [
        "len(binary_idx)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7387"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBMfW6EETwHv"
      },
      "source": [
        "df['Binary'] = binary_idx"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tevZUhLpscJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size = 0.20, random_state = 42,stratify = df['Binary'])\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Hv8ftkycpuo7",
        "outputId": "56c4fc36-21c9-44aa-b4ea-73eea57fd063"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>label</th>\n",
              "      <th>Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/ameri...</td>\n",
              "      <td>american_bulldog</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/germa...</td>\n",
              "      <td>german_shorthaired</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Abyss...</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Persi...</td>\n",
              "      <td>Persian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/ameri...</td>\n",
              "      <td>american_bulldog</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/chihu...</td>\n",
              "      <td>chihuahua</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5905</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Bomba...</td>\n",
              "      <td>Bombay</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5906</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/engli...</td>\n",
              "      <td>english_cocker_spaniel</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5907</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/staff...</td>\n",
              "      <td>staffordshire_bull_terrier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5908</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Bomba...</td>\n",
              "      <td>Bombay</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             image_path  ... Binary\n",
              "0     /content/drive/MyDrive/oxford_pet/images/ameri...  ...      1\n",
              "1     /content/drive/MyDrive/oxford_pet/images/germa...  ...      1\n",
              "2     /content/drive/MyDrive/oxford_pet/images/Abyss...  ...      0\n",
              "3     /content/drive/MyDrive/oxford_pet/images/Persi...  ...      0\n",
              "4     /content/drive/MyDrive/oxford_pet/images/ameri...  ...      1\n",
              "...                                                 ...  ...    ...\n",
              "5904  /content/drive/MyDrive/oxford_pet/images/chihu...  ...      1\n",
              "5905  /content/drive/MyDrive/oxford_pet/images/Bomba...  ...      0\n",
              "5906  /content/drive/MyDrive/oxford_pet/images/engli...  ...      1\n",
              "5907  /content/drive/MyDrive/oxford_pet/images/staff...  ...      1\n",
              "5908  /content/drive/MyDrive/oxford_pet/images/Bomba...  ...      0\n",
              "\n",
              "[5909 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czd620gkpu-q"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, data_path,labels,transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        image = image.resize((256,256))\n",
        "        image = np.array(image)\n",
        "        image = image/255.0\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed['image']\n",
        "        image = image.transpose(2,0,1)\n",
        "        image = torch.as_tensor(image.copy())\n",
        "        sample = {'image':image, 'label' : label}\n",
        "        return sample\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6N4Dczp_OH"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "     A.HorizontalFlip(p=0.5),\n",
        "     A.VerticalFlip(p=0.5),\n",
        "     A.OneOf([A.ShiftScaleRotate(shift_limit = 0.1,rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "             # affine 변환\n",
        "             A.IAAAffine(shear=15, p=0.5, mode= 'constant')],p = 0.8),     \n",
        "     A.RandomBrightnessContrast(p = 0.8),\n",
        "     ]\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-74EEUBqBmz"
      },
      "source": [
        "train_image_path = train_df['image_path'].values\n",
        "train_label = train_df['Binary'].astype('uint8').values\n",
        "test_image_path = test_df['image_path'].values\n",
        "test_label = test_df['Binary'].astype('uint8').values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhBTbz-rVpR"
      },
      "source": [
        "train_data = Dataset(train_image_path,train_label,transform = train_transform)\n",
        "test_data = Dataset(test_image_path,test_label)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NwhN5yvqCIG"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE3aSga9qGnq"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hxDZ-UFLvxa"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,in_channel,out_channel):\n",
        "    super(MLP,self).__init__()\n",
        "    self.linear = nn.Linear(in_channel,out_channel,bias = True)\n",
        "    self.batchnorm = nn.BatchNorm1d(out_channel)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    layer = self.linear(x)\n",
        "    layer = self.batchnorm(layer)\n",
        "    layer = self.relu(layer)\n",
        "    return layer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzA3wehuqHEF"
      },
      "source": [
        "import torch.nn as nn\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear = False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp1 = MLP(262144,128)\n",
        "        self.mlp2 = MLP(128,64)\n",
        "        self.out = MLP(64,n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x2 = nn.Dropout(0.3)(x2)\n",
        "        x3 = self.down2(x2)\n",
        "        x3 = nn.Dropout(0.3)(x3)        \n",
        "        x4 = self.down3(x3)\n",
        "        x4 = nn.Dropout(0.3)(x4)        \n",
        "        x5 = self.down4(x4)\n",
        "        x5 = nn.Dropout(0.3)(x5)\n",
        "        flat = self.flatten(x5)\n",
        "        layer = nn.Dropout(0.5)(flat)\n",
        "        layer = self.mlp1(layer)\n",
        "        layer = nn.Dropout(0.5)(layer)\n",
        "        layer = self.mlp2(layer)\n",
        "        layer = nn.Dropout(0.5)(layer)\n",
        "        layer = self.out(layer)\n",
        "        return layer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-1A55IYqK46"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = UNet(3,2).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHH21U86qMOl",
        "outputId": "4aec1c9d-b504-4482-a71b-87460b0e06e5"
      },
      "source": [
        "summary(net,(3,256,256))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
            "              ReLU-6         [-1, 64, 256, 256]               0\n",
            "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
            "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
            "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
            "             ReLU-11        [-1, 128, 128, 128]               0\n",
            "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
            "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
            "             ReLU-14        [-1, 128, 128, 128]               0\n",
            "       DoubleConv-15        [-1, 128, 128, 128]               0\n",
            "             Down-16        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
            "           Conv2d-18          [-1, 256, 64, 64]         295,168\n",
            "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
            "             ReLU-20          [-1, 256, 64, 64]               0\n",
            "           Conv2d-21          [-1, 256, 64, 64]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 64, 64]             512\n",
            "             ReLU-23          [-1, 256, 64, 64]               0\n",
            "       DoubleConv-24          [-1, 256, 64, 64]               0\n",
            "             Down-25          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
            "           Conv2d-27          [-1, 512, 32, 32]       1,180,160\n",
            "      BatchNorm2d-28          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-29          [-1, 512, 32, 32]               0\n",
            "           Conv2d-30          [-1, 512, 32, 32]       2,359,808\n",
            "      BatchNorm2d-31          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-32          [-1, 512, 32, 32]               0\n",
            "       DoubleConv-33          [-1, 512, 32, 32]               0\n",
            "             Down-34          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
            "           Conv2d-36         [-1, 1024, 16, 16]       4,719,616\n",
            "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-38         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-39         [-1, 1024, 16, 16]       9,438,208\n",
            "      BatchNorm2d-40         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-41         [-1, 1024, 16, 16]               0\n",
            "       DoubleConv-42         [-1, 1024, 16, 16]               0\n",
            "             Down-43         [-1, 1024, 16, 16]               0\n",
            "          Flatten-44               [-1, 262144]               0\n",
            "           Linear-45                  [-1, 128]      33,554,560\n",
            "      BatchNorm1d-46                  [-1, 128]             256\n",
            "             ReLU-47                  [-1, 128]               0\n",
            "              MLP-48                  [-1, 128]               0\n",
            "           Linear-49                   [-1, 64]           8,256\n",
            "      BatchNorm1d-50                   [-1, 64]             128\n",
            "             ReLU-51                   [-1, 64]               0\n",
            "              MLP-52                   [-1, 64]               0\n",
            "           Linear-53                    [-1, 2]             130\n",
            "      BatchNorm1d-54                    [-1, 2]               4\n",
            "             ReLU-55                    [-1, 2]               0\n",
            "              MLP-56                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 52,414,470\n",
            "Trainable params: 52,414,470\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 481.01\n",
            "Params size (MB): 199.95\n",
            "Estimated Total Size (MB): 681.70\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sznTr7N4Ans"
      },
      "source": [
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-5,weight_decay=0.001)\n",
        "train_loss= list()\n",
        "train_acc = list()\n",
        "loss_val = list()\n",
        "val_acc = list()\n",
        "PATH = '/content/drive/MyDrive/oxford_pet/check_points'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IelGKt6_qVe8",
        "outputId": "c1948852-ba4c-44ce-c4df-f1629c927df9"
      },
      "source": [
        "import time\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        " \n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4,weight_decay=1e-4)\n",
        "train_loss= list()\n",
        "train_acc = list()\n",
        "loss_val = list()\n",
        "val_acc = list()\n",
        "PATH = '/content/drive/MyDrive/oxford_pet/check_points'\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # Train Mode\n",
        "    net.train()\n",
        "    start  = time.time()\n",
        "    correct = 0\n",
        "    cost = 0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        inputs = data['image'].to(device= device, dtype = torch.float32)\n",
        "        labels = torch.as_tensor(np.array(data['label'])).to(device= device, dtype = torch.long)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(inputs)\n",
        "        loss = criterion(output, labels)   # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cost += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    torch.save({\n",
        "          'model': net.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'epoch' : epoch\n",
        "          }, PATH+'U-Net_binary_clf_epoch{}_checkpoint'.format(epoch))\n",
        "\n",
        "    print('Train Epoch: {},Loss: {:.4f}, Accuracy: {}/{} ({:.2f}%), time :{:.0f}'.format(\n",
        "                epoch, cost/len(train_loader),correct,len(train_loader.dataset),\n",
        "                100 * correct / len(train_loader.dataset),time.time()-start))\n",
        "    train_loss.append(cost/len(train_loader))\n",
        "    train_acc.append(100 * correct / len(train_loader.dataset))\n",
        "    # Test mode\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            test_inputs = data['image'].to(device = device, dtype = torch.float32)\n",
        "            test_labels = torch.as_tensor(np.array(data['label'])).to(device= device, dtype = torch.long)\n",
        "            test_output = net(test_inputs)\n",
        "            test_loss += criterion(test_output, test_labels).item() # sum up batch loss\n",
        "            pred = test_output.argmax(dim=1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(test_labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    loss_val.append(test_loss)\n",
        "    val_acc.append(100 * correct / len(test_loader.dataset))\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100 * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1,Loss: 0.6923, Accuracy: 2851/5909 (48.25%), time :133\n",
            "Test set: Average loss: 0.6707, Accuracy: 763/1478 (51.62%)\n",
            "\n",
            "Train Epoch: 2,Loss: 0.6631, Accuracy: 3092/5909 (52.33%), time :133\n",
            "Test set: Average loss: 0.6642, Accuracy: 800/1478 (54.13%)\n",
            "\n",
            "Train Epoch: 3,Loss: 0.6493, Accuracy: 3326/5909 (56.29%), time :134\n",
            "Test set: Average loss: 0.6432, Accuracy: 847/1478 (57.31%)\n",
            "\n",
            "Train Epoch: 4,Loss: 0.6209, Accuracy: 3572/5909 (60.45%), time :134\n",
            "Test set: Average loss: 0.5916, Accuracy: 950/1478 (64.28%)\n",
            "\n",
            "Train Epoch: 5,Loss: 0.6159, Accuracy: 3679/5909 (62.26%), time :133\n",
            "Test set: Average loss: 0.6002, Accuracy: 984/1478 (66.58%)\n",
            "\n",
            "Train Epoch: 6,Loss: 0.5988, Accuracy: 3802/5909 (64.34%), time :134\n",
            "Test set: Average loss: 0.5736, Accuracy: 1042/1478 (70.50%)\n",
            "\n",
            "Train Epoch: 7,Loss: 0.5804, Accuracy: 4011/5909 (67.88%), time :134\n",
            "Test set: Average loss: 0.5528, Accuracy: 1016/1478 (68.74%)\n",
            "\n",
            "Train Epoch: 8,Loss: 0.5672, Accuracy: 4174/5909 (70.64%), time :133\n",
            "Test set: Average loss: 0.5694, Accuracy: 1069/1478 (72.33%)\n",
            "\n",
            "Train Epoch: 9,Loss: 0.5483, Accuracy: 4157/5909 (70.35%), time :133\n",
            "Test set: Average loss: 0.5895, Accuracy: 929/1478 (62.86%)\n",
            "\n",
            "Train Epoch: 10,Loss: 0.5368, Accuracy: 4283/5909 (72.48%), time :133\n",
            "Test set: Average loss: 0.4839, Accuracy: 1151/1478 (77.88%)\n",
            "\n",
            "Train Epoch: 11,Loss: 0.5163, Accuracy: 4439/5909 (75.12%), time :133\n",
            "Test set: Average loss: 0.5395, Accuracy: 1045/1478 (70.70%)\n",
            "\n",
            "Train Epoch: 12,Loss: 0.5105, Accuracy: 4491/5909 (76.00%), time :133\n",
            "Test set: Average loss: 0.4754, Accuracy: 1171/1478 (79.23%)\n",
            "\n",
            "Train Epoch: 13,Loss: 0.5019, Accuracy: 4560/5909 (77.17%), time :134\n",
            "Test set: Average loss: 0.4711, Accuracy: 1201/1478 (81.26%)\n",
            "\n",
            "Train Epoch: 14,Loss: 0.4905, Accuracy: 4590/5909 (77.68%), time :134\n",
            "Test set: Average loss: 0.4650, Accuracy: 1199/1478 (81.12%)\n",
            "\n",
            "Train Epoch: 15,Loss: 0.4753, Accuracy: 4681/5909 (79.22%), time :134\n",
            "Test set: Average loss: 0.4525, Accuracy: 1211/1478 (81.94%)\n",
            "\n",
            "Train Epoch: 16,Loss: 0.4663, Accuracy: 4685/5909 (79.29%), time :134\n",
            "Test set: Average loss: 0.4252, Accuracy: 1240/1478 (83.90%)\n",
            "\n",
            "Train Epoch: 17,Loss: 0.4499, Accuracy: 4774/5909 (80.79%), time :134\n",
            "Test set: Average loss: 0.5923, Accuracy: 932/1478 (63.06%)\n",
            "\n",
            "Train Epoch: 18,Loss: 0.4434, Accuracy: 4842/5909 (81.94%), time :134\n",
            "Test set: Average loss: 0.4204, Accuracy: 1263/1478 (85.45%)\n",
            "\n",
            "Train Epoch: 19,Loss: 0.4310, Accuracy: 4880/5909 (82.59%), time :133\n",
            "Test set: Average loss: 0.4224, Accuracy: 1226/1478 (82.95%)\n",
            "\n",
            "Train Epoch: 20,Loss: 0.4171, Accuracy: 4954/5909 (83.84%), time :134\n",
            "Test set: Average loss: 0.5904, Accuracy: 994/1478 (67.25%)\n",
            "\n",
            "Train Epoch: 21,Loss: 0.4106, Accuracy: 4979/5909 (84.26%), time :134\n",
            "Test set: Average loss: 0.4056, Accuracy: 1269/1478 (85.86%)\n",
            "\n",
            "Train Epoch: 22,Loss: 0.3910, Accuracy: 5067/5909 (85.75%), time :134\n",
            "Test set: Average loss: 0.4438, Accuracy: 1210/1478 (81.87%)\n",
            "\n",
            "Train Epoch: 23,Loss: 0.3902, Accuracy: 5076/5909 (85.90%), time :134\n",
            "Test set: Average loss: 0.3783, Accuracy: 1285/1478 (86.94%)\n",
            "\n",
            "Train Epoch: 24,Loss: 0.3828, Accuracy: 5100/5909 (86.31%), time :134\n",
            "Test set: Average loss: 0.3728, Accuracy: 1302/1478 (88.09%)\n",
            "\n",
            "Train Epoch: 25,Loss: 0.3770, Accuracy: 5117/5909 (86.60%), time :134\n",
            "Test set: Average loss: 0.3624, Accuracy: 1296/1478 (87.69%)\n",
            "\n",
            "Train Epoch: 26,Loss: 0.3658, Accuracy: 5175/5909 (87.58%), time :135\n",
            "Test set: Average loss: 0.4318, Accuracy: 1220/1478 (82.54%)\n",
            "\n",
            "Train Epoch: 27,Loss: 0.3552, Accuracy: 5234/5909 (88.58%), time :134\n",
            "Test set: Average loss: 0.4014, Accuracy: 1260/1478 (85.25%)\n",
            "\n",
            "Train Epoch: 28,Loss: 0.3553, Accuracy: 5178/5909 (87.63%), time :134\n",
            "Test set: Average loss: 0.3402, Accuracy: 1321/1478 (89.38%)\n",
            "\n",
            "Train Epoch: 29,Loss: 0.3369, Accuracy: 5285/5909 (89.44%), time :134\n",
            "Test set: Average loss: 0.3230, Accuracy: 1323/1478 (89.51%)\n",
            "\n",
            "Train Epoch: 30,Loss: 0.3313, Accuracy: 5278/5909 (89.32%), time :134\n",
            "Test set: Average loss: 0.3503, Accuracy: 1273/1478 (86.13%)\n",
            "\n",
            "Train Epoch: 31,Loss: 0.3182, Accuracy: 5351/5909 (90.56%), time :134\n",
            "Test set: Average loss: 0.3319, Accuracy: 1309/1478 (88.57%)\n",
            "\n",
            "Train Epoch: 32,Loss: 0.3178, Accuracy: 5329/5909 (90.18%), time :134\n",
            "Test set: Average loss: 0.4289, Accuracy: 1171/1478 (79.23%)\n",
            "\n",
            "Train Epoch: 33,Loss: 0.3131, Accuracy: 5327/5909 (90.15%), time :134\n",
            "Test set: Average loss: 0.2993, Accuracy: 1358/1478 (91.88%)\n",
            "\n",
            "Train Epoch: 34,Loss: 0.3022, Accuracy: 5373/5909 (90.93%), time :134\n",
            "Test set: Average loss: 0.3328, Accuracy: 1299/1478 (87.89%)\n",
            "\n",
            "Train Epoch: 35,Loss: 0.3011, Accuracy: 5367/5909 (90.83%), time :134\n",
            "Test set: Average loss: 0.3021, Accuracy: 1336/1478 (90.39%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV1aRkGhqcKi"
      },
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('u-net Model Accuracy', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Accuaracy', fontsize = 15)\n",
        "plt.xlim(0,19) \n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgnsp5veqXsn"
      },
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(loss_val)\n",
        "plt.title('u-net Model Loss', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Loss', fontsize = 15)\n",
        "plt.ylim(0,1.3)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYpz7eNern60"
      },
      "source": [
        "path = '/content/drive/MyDrive/oxford_pet/seventhh_u-net_clf_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYxSh9D57XFU"
      },
      "source": [
        "pred = F.softmax(masks_pred,dim = 1)\n",
        "prediction = torch.argmax(pred,dim = 1)\n",
        "prediction[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQKp83CTqV2B"
      },
      "source": [
        "torch.save(net.state_dict(),path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRP8RWN_rf1t"
      },
      "source": [
        "plt.imshow(inputs[1].permute(1,2,0).cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov1jzm9aCp1M"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4z2JNfP787-"
      },
      "source": [
        "plt.imshow(masks[1].cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtetGLZ8T7u"
      },
      "source": [
        "plt.imshow(prediction[1].cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DacbuUZ08a8K"
      },
      "source": [
        "mIoU(masks_pred[0],labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5bG4FW_nt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}