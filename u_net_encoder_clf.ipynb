{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "u-net encoder clf.ipyb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19AOWsmZSJmPYcp15qIBIzLMqKo-JCnE5",
      "authorship_tag": "ABX9TyO6oG7+22ETZkkdSrX6yMFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hyun-park/training/blob/master/u_net_encoder_clf_ipyb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1aIscQYpaIC"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "import torch.nn.functional as F\n",
        "import albumentations.pytorch\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import os\n",
        "import re\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvWNBEWBpdSJ"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "lr = 0.001\n",
        "momentum = 0.99\n",
        "\n",
        "batch_size = 32\n",
        "test_batch_size = 3\n",
        "\n",
        "epochs = 300\n",
        "log_interval = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfHGXc8Tc8JO"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3VRucOfpfro"
      },
      "source": [
        "path = '/content/drive/MyDrive/oxford_pet'\n",
        "image_path =os.path.join(path+'/images')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_JAsI0Opfuo"
      },
      "source": [
        "image_path_list = glob(image_path+'/*.jpg')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GxSzCpZrMCu"
      },
      "source": [
        "label_list = list()\n",
        "for path in image_path_list:\n",
        "    label_list.append(re.sub('_\\d+','',path).split('/')[-1].split('.')[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VzjVgBXQ7HE",
        "outputId": "c45a939d-29c0-404b-fda7-9c01d51e337a"
      },
      "source": [
        "class_list = set()\n",
        "for path in image_path_list:\n",
        "  file_name = os.path.splitext(path)[0]\n",
        "  class_name = re.sub('_\\d+','',file_name).split('/')[-1]\n",
        "  class_list.add(class_name)\n",
        "class_list = sorted(list(class_list))\n",
        "\n",
        "class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n",
        "class2idx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abyssinian': 0,\n",
              " 'Bengal': 1,\n",
              " 'Birman': 2,\n",
              " 'Bombay': 3,\n",
              " 'British_Shorthair': 4,\n",
              " 'Egyptian_Mau': 5,\n",
              " 'Maine_Coon': 6,\n",
              " 'Persian': 7,\n",
              " 'Ragdoll': 8,\n",
              " 'Russian_Blue': 9,\n",
              " 'Siamese': 10,\n",
              " 'Sphynx': 11,\n",
              " 'american_bulldog': 12,\n",
              " 'american_pit_bull_terrier': 13,\n",
              " 'basset_hound': 14,\n",
              " 'beagle': 15,\n",
              " 'boxer': 16,\n",
              " 'chihuahua': 17,\n",
              " 'english_cocker_spaniel': 18,\n",
              " 'english_setter': 19,\n",
              " 'german_shorthaired': 20,\n",
              " 'great_pyrenees': 21,\n",
              " 'havanese': 22,\n",
              " 'japanese_chin': 23,\n",
              " 'keeshond': 24,\n",
              " 'leonberger': 25,\n",
              " 'miniature_pinscher': 26,\n",
              " 'newfoundland': 27,\n",
              " 'pomeranian': 28,\n",
              " 'pug': 29,\n",
              " 'saint_bernard': 30,\n",
              " 'samoyed': 31,\n",
              " 'scottish_terrier': 32,\n",
              " 'shiba_inu': 33,\n",
              " 'staffordshire_bull_terrier': 34,\n",
              " 'wheaten_terrier': 35,\n",
              " 'yorkshire_terrier': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tMgJ-X-pjIt"
      },
      "source": [
        "df= pd.DataFrame(list(zip(image_path_list,label_list)),index = range(len(image_path_list)),columns = ['image_path','label'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tevZUhLpscJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size = 0.20, random_state = 42,stratify = df['label'])\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Hv8ftkycpuo7",
        "outputId": "e6d7186b-5eb7-43ba-f9e8-c2542fc7c6c4"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/yorks...</td>\n",
              "      <td>yorkshire_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/havan...</td>\n",
              "      <td>havanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/minia...</td>\n",
              "      <td>miniature_pinscher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Birma...</td>\n",
              "      <td>Birman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/engli...</td>\n",
              "      <td>english_setter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/minia...</td>\n",
              "      <td>miniature_pinscher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5905</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/minia...</td>\n",
              "      <td>miniature_pinscher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5906</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/Abyss...</td>\n",
              "      <td>Abyssinian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5907</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/wheat...</td>\n",
              "      <td>wheaten_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5908</th>\n",
              "      <td>/content/drive/MyDrive/oxford_pet/images/basse...</td>\n",
              "      <td>basset_hound</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             image_path               label\n",
              "0     /content/drive/MyDrive/oxford_pet/images/yorks...   yorkshire_terrier\n",
              "1     /content/drive/MyDrive/oxford_pet/images/havan...            havanese\n",
              "2     /content/drive/MyDrive/oxford_pet/images/minia...  miniature_pinscher\n",
              "3     /content/drive/MyDrive/oxford_pet/images/Birma...              Birman\n",
              "4     /content/drive/MyDrive/oxford_pet/images/engli...      english_setter\n",
              "...                                                 ...                 ...\n",
              "5904  /content/drive/MyDrive/oxford_pet/images/minia...  miniature_pinscher\n",
              "5905  /content/drive/MyDrive/oxford_pet/images/minia...  miniature_pinscher\n",
              "5906  /content/drive/MyDrive/oxford_pet/images/Abyss...          Abyssinian\n",
              "5907  /content/drive/MyDrive/oxford_pet/images/wheat...     wheaten_terrier\n",
              "5908  /content/drive/MyDrive/oxford_pet/images/basse...        basset_hound\n",
              "\n",
              "[5909 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czd620gkpu-q"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, data_path, transform = None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data_path)\n",
        "    def __getitem__(self,idx):\n",
        "        path = self.data_path[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        image = image.resize((256,256))\n",
        "        image = np.array(image)\n",
        "        image = image/255.0\n",
        "\n",
        "        label = re.sub('_\\d+','',path).split('/')[-1].split('.')[0]\n",
        "        label_idx = class2idx[label]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed['image']\n",
        "        image = image.transpose(2,0,1)\n",
        "        image = torch.as_tensor(image.copy())\n",
        "        sample = {'image':image, 'label' : label_idx}\n",
        "        return sample\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6N4Dczp_OH"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "     A.HorizontalFlip(p=0.5),\n",
        "     A.VerticalFlip(p=0.5),\n",
        "     A.OneOf([A.ShiftScaleRotate(shift_limit = 0.1,rotate_limit=15, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "             # affine 변환\n",
        "             A.IAAAffine(shear=15, p=0.5, mode= 'constant')],p = 0.8),     \n",
        "     A.RandomBrightnessContrast(p = 0.8),\n",
        "     ]\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-74EEUBqBmz"
      },
      "source": [
        "train_image_path = train_df['image_path'].values\n",
        "train_label = train_df['label'].values\n",
        "test_image_path = test_df['image_path'].values\n",
        "test_label = test_df['label'].values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhBTbz-rVpR"
      },
      "source": [
        "train_data = Dataset(train_image_path,transform = train_transform)\n",
        "test_data = Dataset(test_image_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NwhN5yvqCIG"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE3aSga9qGnq"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hxDZ-UFLvxa"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,in_channel,out_channel):\n",
        "    super(MLP,self).__init__()\n",
        "    self.linear = nn.Linear(in_channel,out_channel,bias = True)\n",
        "    self.batchnorm = nn.BatchNorm1d(out_channel)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    layer = self.linear(x)\n",
        "    layer = self.batchnorm(layer)\n",
        "    layer = self.relu(layer)\n",
        "    return layer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzA3wehuqHEF"
      },
      "source": [
        "import torch.nn as nn\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear = False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp1 = MLP(262144,64)\n",
        "        self.mlp2 = MLP(64,64)\n",
        "        self.out = MLP(64,37)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x2 = nn.Dropout(0.3)(x2)\n",
        "        x3 = self.down2(x2)\n",
        "        x3 = nn.Dropout(0.3)(x3)        \n",
        "        x4 = self.down3(x3)\n",
        "        x4 = nn.Dropout(0.3)(x4)        \n",
        "        x5 = self.down4(x4)\n",
        "        x5 = nn.Dropout(0.3)(x5)\n",
        "        flat = self.flatten(x5)\n",
        "        layer = nn.Dropout(0.5)(flat)\n",
        "        layer = self.mlp1(layer)\n",
        "        layer = nn.Dropout(0.5)(layer)\n",
        "        layer = self.mlp2(layer)\n",
        "        layer = nn.Dropout(0.5)(layer)\n",
        "        layer = self.out(layer)\n",
        "        return layer"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-1A55IYqK46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4278a6ef-f5da-415b-8e71-6be936176423"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = UNet(3,37).to(device)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/oxford_pet/check_pointsU-Net_clf_epoch83_checkpoint')\n",
        "net.load_state_dict(checkpoint['model'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHH21U86qMOl",
        "outputId": "726dcc8e-5909-4b65-d01b-02c5d260f0da"
      },
      "source": [
        "summary(net,(3,256,256))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
            "              ReLU-6         [-1, 64, 256, 256]               0\n",
            "        DoubleConv-7         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
            "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
            "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
            "             ReLU-11        [-1, 128, 128, 128]               0\n",
            "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
            "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
            "             ReLU-14        [-1, 128, 128, 128]               0\n",
            "       DoubleConv-15        [-1, 128, 128, 128]               0\n",
            "             Down-16        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
            "           Conv2d-18          [-1, 256, 64, 64]         295,168\n",
            "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
            "             ReLU-20          [-1, 256, 64, 64]               0\n",
            "           Conv2d-21          [-1, 256, 64, 64]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 64, 64]             512\n",
            "             ReLU-23          [-1, 256, 64, 64]               0\n",
            "       DoubleConv-24          [-1, 256, 64, 64]               0\n",
            "             Down-25          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
            "           Conv2d-27          [-1, 512, 32, 32]       1,180,160\n",
            "      BatchNorm2d-28          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-29          [-1, 512, 32, 32]               0\n",
            "           Conv2d-30          [-1, 512, 32, 32]       2,359,808\n",
            "      BatchNorm2d-31          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-32          [-1, 512, 32, 32]               0\n",
            "       DoubleConv-33          [-1, 512, 32, 32]               0\n",
            "             Down-34          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
            "           Conv2d-36         [-1, 1024, 16, 16]       4,719,616\n",
            "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-38         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-39         [-1, 1024, 16, 16]       9,438,208\n",
            "      BatchNorm2d-40         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-41         [-1, 1024, 16, 16]               0\n",
            "       DoubleConv-42         [-1, 1024, 16, 16]               0\n",
            "             Down-43         [-1, 1024, 16, 16]               0\n",
            "          Flatten-44               [-1, 262144]               0\n",
            "           Linear-45                   [-1, 64]      16,777,280\n",
            "      BatchNorm1d-46                   [-1, 64]             128\n",
            "             ReLU-47                   [-1, 64]               0\n",
            "              MLP-48                   [-1, 64]               0\n",
            "           Linear-49                   [-1, 64]           4,160\n",
            "      BatchNorm1d-50                   [-1, 64]             128\n",
            "             ReLU-51                   [-1, 64]               0\n",
            "              MLP-52                   [-1, 64]               0\n",
            "           Linear-53                   [-1, 37]           2,405\n",
            "      BatchNorm1d-54                   [-1, 37]              74\n",
            "             ReLU-55                   [-1, 37]               0\n",
            "              MLP-56                   [-1, 37]               0\n",
            "================================================================\n",
            "Total params: 35,635,311\n",
            "Trainable params: 35,635,311\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 481.01\n",
            "Params size (MB): 135.94\n",
            "Estimated Total Size (MB): 617.69\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sznTr7N4Ans"
      },
      "source": [
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-5,weight_decay=1e-4)\n",
        "train_loss= list()\n",
        "train_acc = list()\n",
        "loss_val = list()\n",
        "val_acc = list()\n",
        "PATH = '/content/drive/MyDrive/oxford_pet/check_points'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IelGKt6_qVe8",
        "outputId": "3a21cfa5-333b-4f41-e7b1-47d41084bf7e"
      },
      "source": [
        "import time\n",
        "import argparse\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        " \n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4,weight_decay=1e-4)\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "train_loss= list()\n",
        "train_acc = list()\n",
        "loss_val = list()\n",
        "val_acc = list()\n",
        "PATH = '/content/drive/MyDrive/oxford_pet/check_points'\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # Train Mode\n",
        "    net.train()\n",
        "    start  = time.time()\n",
        "    correct = 0\n",
        "    cost = 0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        inputs = data['image'].to(device= device, dtype = torch.float32)\n",
        "        labels = data['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(inputs)\n",
        "        loss = criterion(output, labels)   # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cost += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    torch.save({\n",
        "          'model': net.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'epoch' : epoch\n",
        "          }, PATH+'U-Net_clf_epoch{}_checkpoint'.format(epoch))\n",
        "\n",
        "    print('Train Epoch: {},Loss: {:.6f}, Accuracy: {}/{} ({:.0f}%), time :{}'.format(\n",
        "                epoch, cost/len(train_loader),correct,len(train_loader.dataset),\n",
        "                100 * correct / len(train_loader.dataset),time.time()-start))\n",
        "    train_loss.append(cost/len(train_loader))\n",
        "    train_acc.append(100 * correct / len(train_loader.dataset))\n",
        "    # Test mode\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            inputs, labels = data['image'].to(device = device, dtype = torch.float32), data['label'].to(device)\n",
        "            output = net(inputs)\n",
        "            test_loss += criterion(output, labels).item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    loss_val.append(test_loss)\n",
        "    val_acc.append(100 * correct / len(test_loader.dataset))\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100 * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1,Loss: 2.362527, Accuracy: 2033/5909 (34%), time :3105.1260249614716\n",
            "Test set: Average loss: 2.5116, Accuracy: 461/1478 (31%)\n",
            "\n",
            "Train Epoch: 2,Loss: 2.375939, Accuracy: 1997/5909 (34%), time :155.77051329612732\n",
            "Test set: Average loss: 2.4525, Accuracy: 464/1478 (31%)\n",
            "\n",
            "Train Epoch: 3,Loss: 2.332166, Accuracy: 2073/5909 (35%), time :156.36928915977478\n",
            "Test set: Average loss: 2.3951, Accuracy: 510/1478 (35%)\n",
            "\n",
            "Train Epoch: 4,Loss: 2.339585, Accuracy: 2047/5909 (35%), time :155.71021270751953\n",
            "Test set: Average loss: 2.3658, Accuracy: 500/1478 (34%)\n",
            "\n",
            "Train Epoch: 5,Loss: 2.314208, Accuracy: 2071/5909 (35%), time :157.83364272117615\n",
            "Test set: Average loss: 2.3157, Accuracy: 510/1478 (35%)\n",
            "\n",
            "Train Epoch: 6,Loss: 2.307766, Accuracy: 2081/5909 (35%), time :155.92538452148438\n",
            "Test set: Average loss: 2.3711, Accuracy: 496/1478 (34%)\n",
            "\n",
            "Train Epoch: 7,Loss: 2.289267, Accuracy: 2076/5909 (35%), time :155.23796820640564\n",
            "Test set: Average loss: 2.2821, Accuracy: 523/1478 (35%)\n",
            "\n",
            "Train Epoch: 8,Loss: 2.287103, Accuracy: 2153/5909 (36%), time :155.6484215259552\n",
            "Test set: Average loss: 2.2305, Accuracy: 556/1478 (38%)\n",
            "\n",
            "Train Epoch: 9,Loss: 2.264568, Accuracy: 2135/5909 (36%), time :158.37848043441772\n",
            "Test set: Average loss: 2.2326, Accuracy: 562/1478 (38%)\n",
            "\n",
            "Train Epoch: 10,Loss: 2.243942, Accuracy: 2208/5909 (37%), time :157.06727194786072\n",
            "Test set: Average loss: 2.2759, Accuracy: 574/1478 (39%)\n",
            "\n",
            "Train Epoch: 11,Loss: 2.225195, Accuracy: 2197/5909 (37%), time :158.73512744903564\n",
            "Test set: Average loss: 2.2167, Accuracy: 544/1478 (37%)\n",
            "\n",
            "Train Epoch: 12,Loss: 2.237573, Accuracy: 2234/5909 (38%), time :157.65347385406494\n",
            "Test set: Average loss: 2.2640, Accuracy: 543/1478 (37%)\n",
            "\n",
            "Train Epoch: 13,Loss: 2.211450, Accuracy: 2224/5909 (38%), time :155.8566038608551\n",
            "Test set: Average loss: 2.2880, Accuracy: 552/1478 (37%)\n",
            "\n",
            "Train Epoch: 14,Loss: 2.199751, Accuracy: 2240/5909 (38%), time :158.94429349899292\n",
            "Test set: Average loss: 2.2745, Accuracy: 568/1478 (38%)\n",
            "\n",
            "Train Epoch: 15,Loss: 2.201528, Accuracy: 2262/5909 (38%), time :159.63427639007568\n",
            "Test set: Average loss: 2.2584, Accuracy: 559/1478 (38%)\n",
            "\n",
            "Train Epoch: 16,Loss: 2.175896, Accuracy: 2337/5909 (40%), time :157.62242078781128\n",
            "Test set: Average loss: 2.2769, Accuracy: 551/1478 (37%)\n",
            "\n",
            "Train Epoch: 17,Loss: 2.160688, Accuracy: 2334/5909 (39%), time :156.51400542259216\n",
            "Test set: Average loss: 2.1797, Accuracy: 587/1478 (40%)\n",
            "\n",
            "Train Epoch: 18,Loss: 2.148465, Accuracy: 2323/5909 (39%), time :158.42217922210693\n",
            "Test set: Average loss: 2.2506, Accuracy: 551/1478 (37%)\n",
            "\n",
            "Train Epoch: 19,Loss: 2.153444, Accuracy: 2303/5909 (39%), time :161.4587962627411\n",
            "Test set: Average loss: 2.3167, Accuracy: 544/1478 (37%)\n",
            "\n",
            "Train Epoch: 20,Loss: 2.129206, Accuracy: 2331/5909 (39%), time :157.06684637069702\n",
            "Test set: Average loss: 2.3880, Accuracy: 511/1478 (35%)\n",
            "\n",
            "Train Epoch: 21,Loss: 2.103196, Accuracy: 2396/5909 (41%), time :158.38525223731995\n",
            "Test set: Average loss: 2.2708, Accuracy: 547/1478 (37%)\n",
            "\n",
            "Train Epoch: 22,Loss: 2.105478, Accuracy: 2386/5909 (40%), time :156.61413884162903\n",
            "Test set: Average loss: 2.1273, Accuracy: 632/1478 (43%)\n",
            "\n",
            "Train Epoch: 23,Loss: 2.074410, Accuracy: 2403/5909 (41%), time :154.8914818763733\n",
            "Test set: Average loss: 2.2300, Accuracy: 590/1478 (40%)\n",
            "\n",
            "Train Epoch: 24,Loss: 2.075013, Accuracy: 2448/5909 (41%), time :156.19726538658142\n",
            "Test set: Average loss: 2.1702, Accuracy: 582/1478 (39%)\n",
            "\n",
            "Train Epoch: 25,Loss: 2.067954, Accuracy: 2437/5909 (41%), time :155.14351201057434\n",
            "Test set: Average loss: 2.0571, Accuracy: 635/1478 (43%)\n",
            "\n",
            "Train Epoch: 26,Loss: 2.054423, Accuracy: 2505/5909 (42%), time :155.95610737800598\n",
            "Test set: Average loss: 2.1391, Accuracy: 590/1478 (40%)\n",
            "\n",
            "Train Epoch: 27,Loss: 2.053365, Accuracy: 2484/5909 (42%), time :155.79509806632996\n",
            "Test set: Average loss: 2.0804, Accuracy: 622/1478 (42%)\n",
            "\n",
            "Train Epoch: 28,Loss: 2.004995, Accuracy: 2592/5909 (44%), time :157.46414494514465\n",
            "Test set: Average loss: 2.1321, Accuracy: 610/1478 (41%)\n",
            "\n",
            "Train Epoch: 29,Loss: 2.022141, Accuracy: 2494/5909 (42%), time :155.34200263023376\n",
            "Test set: Average loss: 2.0545, Accuracy: 648/1478 (44%)\n",
            "\n",
            "Train Epoch: 30,Loss: 2.006137, Accuracy: 2508/5909 (42%), time :157.59183645248413\n",
            "Test set: Average loss: 2.1543, Accuracy: 611/1478 (41%)\n",
            "\n",
            "Train Epoch: 31,Loss: 2.009287, Accuracy: 2559/5909 (43%), time :157.09714436531067\n",
            "Test set: Average loss: 2.0332, Accuracy: 632/1478 (43%)\n",
            "\n",
            "Train Epoch: 32,Loss: 1.978043, Accuracy: 2598/5909 (44%), time :156.16562342643738\n",
            "Test set: Average loss: 2.0264, Accuracy: 648/1478 (44%)\n",
            "\n",
            "Train Epoch: 33,Loss: 1.975908, Accuracy: 2583/5909 (44%), time :159.21154642105103\n",
            "Test set: Average loss: 1.9847, Accuracy: 677/1478 (46%)\n",
            "\n",
            "Train Epoch: 34,Loss: 1.943827, Accuracy: 2658/5909 (45%), time :157.9558970928192\n",
            "Test set: Average loss: 2.0446, Accuracy: 636/1478 (43%)\n",
            "\n",
            "Train Epoch: 35,Loss: 1.943548, Accuracy: 2689/5909 (46%), time :156.60000801086426\n",
            "Test set: Average loss: 2.1033, Accuracy: 598/1478 (40%)\n",
            "\n",
            "Train Epoch: 36,Loss: 1.942443, Accuracy: 2619/5909 (44%), time :156.26904129981995\n",
            "Test set: Average loss: 2.0344, Accuracy: 632/1478 (43%)\n",
            "\n",
            "Train Epoch: 37,Loss: 1.938973, Accuracy: 2639/5909 (45%), time :155.06537008285522\n",
            "Test set: Average loss: 2.0618, Accuracy: 602/1478 (41%)\n",
            "\n",
            "Train Epoch: 38,Loss: 1.925769, Accuracy: 2655/5909 (45%), time :157.50678944587708\n",
            "Test set: Average loss: 1.9865, Accuracy: 687/1478 (46%)\n",
            "\n",
            "Train Epoch: 39,Loss: 1.921256, Accuracy: 2687/5909 (45%), time :156.25528860092163\n",
            "Test set: Average loss: 2.1640, Accuracy: 561/1478 (38%)\n",
            "\n",
            "Train Epoch: 40,Loss: 1.916686, Accuracy: 2694/5909 (46%), time :156.58817768096924\n",
            "Test set: Average loss: 2.1400, Accuracy: 601/1478 (41%)\n",
            "\n",
            "Train Epoch: 41,Loss: 1.872128, Accuracy: 2769/5909 (47%), time :161.28290271759033\n",
            "Test set: Average loss: 1.9676, Accuracy: 625/1478 (42%)\n",
            "\n",
            "Train Epoch: 42,Loss: 1.880410, Accuracy: 2739/5909 (46%), time :157.86866927146912\n",
            "Test set: Average loss: 2.1244, Accuracy: 612/1478 (41%)\n",
            "\n",
            "Train Epoch: 43,Loss: 1.869295, Accuracy: 2762/5909 (47%), time :158.37962770462036\n",
            "Test set: Average loss: 2.0077, Accuracy: 658/1478 (45%)\n",
            "\n",
            "Train Epoch: 44,Loss: 1.842510, Accuracy: 2826/5909 (48%), time :158.39208602905273\n",
            "Test set: Average loss: 1.9634, Accuracy: 672/1478 (45%)\n",
            "\n",
            "Train Epoch: 45,Loss: 1.846820, Accuracy: 2782/5909 (47%), time :159.84278655052185\n",
            "Test set: Average loss: 1.9088, Accuracy: 690/1478 (47%)\n",
            "\n",
            "Train Epoch: 46,Loss: 1.836097, Accuracy: 2826/5909 (48%), time :155.74342370033264\n",
            "Test set: Average loss: 1.9110, Accuracy: 695/1478 (47%)\n",
            "\n",
            "Train Epoch: 47,Loss: 1.840400, Accuracy: 2774/5909 (47%), time :157.75681710243225\n",
            "Test set: Average loss: 1.9636, Accuracy: 672/1478 (45%)\n",
            "\n",
            "Train Epoch: 48,Loss: 1.826216, Accuracy: 2814/5909 (48%), time :155.79531526565552\n",
            "Test set: Average loss: 2.0314, Accuracy: 646/1478 (44%)\n",
            "\n",
            "Train Epoch: 49,Loss: 1.789543, Accuracy: 2884/5909 (49%), time :157.31850910186768\n",
            "Test set: Average loss: 1.9419, Accuracy: 684/1478 (46%)\n",
            "\n",
            "Train Epoch: 50,Loss: 1.795008, Accuracy: 2900/5909 (49%), time :156.69067287445068\n",
            "Test set: Average loss: 1.9423, Accuracy: 688/1478 (47%)\n",
            "\n",
            "Train Epoch: 51,Loss: 1.768088, Accuracy: 2902/5909 (49%), time :159.15386199951172\n",
            "Test set: Average loss: 1.9027, Accuracy: 681/1478 (46%)\n",
            "\n",
            "Train Epoch: 52,Loss: 1.781152, Accuracy: 2886/5909 (49%), time :161.4373185634613\n",
            "Test set: Average loss: 1.8955, Accuracy: 692/1478 (47%)\n",
            "\n",
            "Train Epoch: 53,Loss: 1.758498, Accuracy: 2923/5909 (49%), time :158.03358387947083\n",
            "Test set: Average loss: 1.8655, Accuracy: 702/1478 (47%)\n",
            "\n",
            "Train Epoch: 54,Loss: 1.763803, Accuracy: 2881/5909 (49%), time :156.15972185134888\n",
            "Test set: Average loss: 1.8535, Accuracy: 699/1478 (47%)\n",
            "\n",
            "Train Epoch: 55,Loss: 1.749080, Accuracy: 2960/5909 (50%), time :155.57411432266235\n",
            "Test set: Average loss: 1.7278, Accuracy: 739/1478 (50%)\n",
            "\n",
            "Train Epoch: 56,Loss: 1.747639, Accuracy: 2930/5909 (50%), time :156.13020634651184\n",
            "Test set: Average loss: 1.9193, Accuracy: 673/1478 (46%)\n",
            "\n",
            "Train Epoch: 57,Loss: 1.733736, Accuracy: 2951/5909 (50%), time :156.59170722961426\n",
            "Test set: Average loss: 1.8238, Accuracy: 718/1478 (49%)\n",
            "\n",
            "Train Epoch: 58,Loss: 1.723897, Accuracy: 2964/5909 (50%), time :157.34543299674988\n",
            "Test set: Average loss: 1.8023, Accuracy: 742/1478 (50%)\n",
            "\n",
            "Train Epoch: 59,Loss: 1.698816, Accuracy: 3054/5909 (52%), time :158.39607000350952\n",
            "Test set: Average loss: 1.7932, Accuracy: 717/1478 (49%)\n",
            "\n",
            "Train Epoch: 60,Loss: 1.706685, Accuracy: 2983/5909 (50%), time :157.5199635028839\n",
            "Test set: Average loss: 1.7610, Accuracy: 731/1478 (49%)\n",
            "\n",
            "Train Epoch: 61,Loss: 1.702039, Accuracy: 3040/5909 (51%), time :158.0037624835968\n",
            "Test set: Average loss: 1.7364, Accuracy: 766/1478 (52%)\n",
            "\n",
            "Train Epoch: 62,Loss: 1.681174, Accuracy: 3095/5909 (52%), time :157.36218523979187\n",
            "Test set: Average loss: 1.7847, Accuracy: 760/1478 (51%)\n",
            "\n",
            "Train Epoch: 63,Loss: 1.680129, Accuracy: 3053/5909 (52%), time :158.91553115844727\n",
            "Test set: Average loss: 1.7767, Accuracy: 737/1478 (50%)\n",
            "\n",
            "Train Epoch: 64,Loss: 1.680093, Accuracy: 3037/5909 (51%), time :158.13317847251892\n",
            "Test set: Average loss: 1.7811, Accuracy: 736/1478 (50%)\n",
            "\n",
            "Train Epoch: 65,Loss: 1.681623, Accuracy: 3025/5909 (51%), time :157.6326620578766\n",
            "Test set: Average loss: 1.7565, Accuracy: 731/1478 (49%)\n",
            "\n",
            "Train Epoch: 66,Loss: 1.670175, Accuracy: 3070/5909 (52%), time :157.73815083503723\n",
            "Test set: Average loss: 1.7378, Accuracy: 734/1478 (50%)\n",
            "\n",
            "Train Epoch: 67,Loss: 1.634639, Accuracy: 3113/5909 (53%), time :159.6906316280365\n",
            "Test set: Average loss: 1.7498, Accuracy: 744/1478 (50%)\n",
            "\n",
            "Train Epoch: 68,Loss: 1.638829, Accuracy: 3093/5909 (52%), time :159.95578336715698\n",
            "Test set: Average loss: 1.7819, Accuracy: 768/1478 (52%)\n",
            "\n",
            "Train Epoch: 69,Loss: 1.617653, Accuracy: 3199/5909 (54%), time :156.42780876159668\n",
            "Test set: Average loss: 1.8052, Accuracy: 729/1478 (49%)\n",
            "\n",
            "Train Epoch: 70,Loss: 1.617945, Accuracy: 3148/5909 (53%), time :159.0260739326477\n",
            "Test set: Average loss: 1.8341, Accuracy: 746/1478 (50%)\n",
            "\n",
            "Train Epoch: 71,Loss: 1.621233, Accuracy: 3147/5909 (53%), time :159.34726977348328\n",
            "Test set: Average loss: 1.7364, Accuracy: 736/1478 (50%)\n",
            "\n",
            "Train Epoch: 72,Loss: 1.605612, Accuracy: 3155/5909 (53%), time :159.73158144950867\n",
            "Test set: Average loss: 1.9386, Accuracy: 684/1478 (46%)\n",
            "\n",
            "Train Epoch: 73,Loss: 1.586645, Accuracy: 3158/5909 (53%), time :158.08902883529663\n",
            "Test set: Average loss: 1.8164, Accuracy: 733/1478 (50%)\n",
            "\n",
            "Train Epoch: 74,Loss: 1.585328, Accuracy: 3166/5909 (54%), time :156.61145162582397\n",
            "Test set: Average loss: 1.6993, Accuracy: 740/1478 (50%)\n",
            "\n",
            "Train Epoch: 75,Loss: 1.574244, Accuracy: 3165/5909 (54%), time :158.7217309474945\n",
            "Test set: Average loss: 1.6242, Accuracy: 781/1478 (53%)\n",
            "\n",
            "Train Epoch: 76,Loss: 1.578202, Accuracy: 3233/5909 (55%), time :157.31919121742249\n",
            "Test set: Average loss: 1.7083, Accuracy: 778/1478 (53%)\n",
            "\n",
            "Train Epoch: 77,Loss: 1.553534, Accuracy: 3234/5909 (55%), time :159.39288783073425\n",
            "Test set: Average loss: 1.7938, Accuracy: 721/1478 (49%)\n",
            "\n",
            "Train Epoch: 78,Loss: 1.541801, Accuracy: 3245/5909 (55%), time :158.46055936813354\n",
            "Test set: Average loss: 1.7521, Accuracy: 752/1478 (51%)\n",
            "\n",
            "Train Epoch: 79,Loss: 1.527665, Accuracy: 3305/5909 (56%), time :156.98940753936768\n",
            "Test set: Average loss: 1.6307, Accuracy: 782/1478 (53%)\n",
            "\n",
            "Train Epoch: 80,Loss: 1.553624, Accuracy: 3184/5909 (54%), time :157.78719329833984\n",
            "Test set: Average loss: 1.7434, Accuracy: 740/1478 (50%)\n",
            "\n",
            "Train Epoch: 81,Loss: 1.531196, Accuracy: 3294/5909 (56%), time :158.8857684135437\n",
            "Test set: Average loss: 1.8025, Accuracy: 718/1478 (49%)\n",
            "\n",
            "Train Epoch: 82,Loss: 1.540708, Accuracy: 3276/5909 (55%), time :157.1345751285553\n",
            "Test set: Average loss: 1.6961, Accuracy: 764/1478 (52%)\n",
            "\n",
            "Train Epoch: 83,Loss: 1.526565, Accuracy: 3301/5909 (56%), time :154.35880255699158\n",
            "Test set: Average loss: 1.5737, Accuracy: 799/1478 (54%)\n",
            "\n",
            "Train Epoch: 84,Loss: 1.523914, Accuracy: 3337/5909 (56%), time :148.86917996406555\n",
            "Test set: Average loss: 1.6460, Accuracy: 777/1478 (53%)\n",
            "\n",
            "Train Epoch: 85,Loss: 1.514456, Accuracy: 3283/5909 (56%), time :148.21931147575378\n",
            "Test set: Average loss: 1.6856, Accuracy: 786/1478 (53%)\n",
            "\n",
            "Train Epoch: 86,Loss: 1.510396, Accuracy: 3296/5909 (56%), time :148.12860369682312\n",
            "Test set: Average loss: 1.7065, Accuracy: 776/1478 (53%)\n",
            "\n",
            "Train Epoch: 87,Loss: 1.492061, Accuracy: 3297/5909 (56%), time :148.7299964427948\n",
            "Test set: Average loss: 1.7737, Accuracy: 749/1478 (51%)\n",
            "\n",
            "Train Epoch: 88,Loss: 1.473355, Accuracy: 3391/5909 (57%), time :148.37253165245056\n",
            "Test set: Average loss: 1.5994, Accuracy: 773/1478 (52%)\n",
            "\n",
            "Train Epoch: 89,Loss: 1.482791, Accuracy: 3367/5909 (57%), time :160.69920992851257\n",
            "Test set: Average loss: 1.7546, Accuracy: 738/1478 (50%)\n",
            "\n",
            "Train Epoch: 90,Loss: 1.481340, Accuracy: 3356/5909 (57%), time :148.13794016838074\n",
            "Test set: Average loss: 1.6248, Accuracy: 793/1478 (54%)\n",
            "\n",
            "Train Epoch: 91,Loss: 1.454757, Accuracy: 3430/5909 (58%), time :148.89499592781067\n",
            "Test set: Average loss: 1.7672, Accuracy: 744/1478 (50%)\n",
            "\n",
            "Train Epoch: 92,Loss: 1.474307, Accuracy: 3329/5909 (56%), time :148.1220383644104\n",
            "Test set: Average loss: 1.6091, Accuracy: 819/1478 (55%)\n",
            "\n",
            "Train Epoch: 93,Loss: 1.442613, Accuracy: 3444/5909 (58%), time :148.43037939071655\n",
            "Test set: Average loss: 1.6636, Accuracy: 775/1478 (52%)\n",
            "\n",
            "Train Epoch: 94,Loss: 1.451511, Accuracy: 3422/5909 (58%), time :148.52229619026184\n",
            "Test set: Average loss: 1.5451, Accuracy: 828/1478 (56%)\n",
            "\n",
            "Train Epoch: 95,Loss: 1.409568, Accuracy: 3519/5909 (60%), time :148.0116868019104\n",
            "Test set: Average loss: 1.5813, Accuracy: 811/1478 (55%)\n",
            "\n",
            "Train Epoch: 96,Loss: 1.404060, Accuracy: 3524/5909 (60%), time :148.2423164844513\n",
            "Test set: Average loss: 1.6005, Accuracy: 798/1478 (54%)\n",
            "\n",
            "Train Epoch: 97,Loss: 1.405298, Accuracy: 3492/5909 (59%), time :148.14186310768127\n",
            "Test set: Average loss: 1.6670, Accuracy: 789/1478 (53%)\n",
            "\n",
            "Train Epoch: 98,Loss: 1.393223, Accuracy: 3491/5909 (59%), time :148.1198389530182\n",
            "Test set: Average loss: 1.6398, Accuracy: 810/1478 (55%)\n",
            "\n",
            "Train Epoch: 99,Loss: 1.396298, Accuracy: 3465/5909 (59%), time :161.65272760391235\n",
            "Test set: Average loss: 1.6318, Accuracy: 805/1478 (54%)\n",
            "\n",
            "Train Epoch: 100,Loss: 1.390358, Accuracy: 3488/5909 (59%), time :148.0801875591278\n",
            "Test set: Average loss: 1.6537, Accuracy: 802/1478 (54%)\n",
            "\n",
            "Train Epoch: 101,Loss: 1.395257, Accuracy: 3484/5909 (59%), time :148.53951215744019\n",
            "Test set: Average loss: 1.6528, Accuracy: 800/1478 (54%)\n",
            "\n",
            "Train Epoch: 102,Loss: 1.410749, Accuracy: 3447/5909 (58%), time :148.15683269500732\n",
            "Test set: Average loss: 1.6598, Accuracy: 801/1478 (54%)\n",
            "\n",
            "Train Epoch: 103,Loss: 1.393642, Accuracy: 3493/5909 (59%), time :148.9835467338562\n",
            "Test set: Average loss: 1.5976, Accuracy: 792/1478 (54%)\n",
            "\n",
            "Train Epoch: 104,Loss: 1.370680, Accuracy: 3524/5909 (60%), time :149.09932160377502\n",
            "Test set: Average loss: 1.6152, Accuracy: 811/1478 (55%)\n",
            "\n",
            "Train Epoch: 105,Loss: 1.358151, Accuracy: 3549/5909 (60%), time :149.4377110004425\n",
            "Test set: Average loss: 1.5545, Accuracy: 825/1478 (56%)\n",
            "\n",
            "Train Epoch: 106,Loss: 1.344036, Accuracy: 3578/5909 (61%), time :148.69143843650818\n",
            "Test set: Average loss: 1.5291, Accuracy: 854/1478 (58%)\n",
            "\n",
            "Train Epoch: 107,Loss: 1.374828, Accuracy: 3495/5909 (59%), time :148.92027115821838\n",
            "Test set: Average loss: 1.5999, Accuracy: 794/1478 (54%)\n",
            "\n",
            "Train Epoch: 108,Loss: 1.351579, Accuracy: 3566/5909 (60%), time :148.58204412460327\n",
            "Test set: Average loss: 1.5040, Accuracy: 856/1478 (58%)\n",
            "\n",
            "Train Epoch: 109,Loss: 1.302773, Accuracy: 3719/5909 (63%), time :164.0315980911255\n",
            "Test set: Average loss: 1.5709, Accuracy: 838/1478 (57%)\n",
            "\n",
            "Train Epoch: 110,Loss: 1.332727, Accuracy: 3571/5909 (60%), time :148.64359521865845\n",
            "Test set: Average loss: 1.5030, Accuracy: 867/1478 (59%)\n",
            "\n",
            "Train Epoch: 111,Loss: 1.319802, Accuracy: 3662/5909 (62%), time :148.57988500595093\n",
            "Test set: Average loss: 1.5353, Accuracy: 821/1478 (56%)\n",
            "\n",
            "Train Epoch: 112,Loss: 1.326353, Accuracy: 3645/5909 (62%), time :148.6260666847229\n",
            "Test set: Average loss: 1.5476, Accuracy: 823/1478 (56%)\n",
            "\n",
            "Train Epoch: 113,Loss: 1.313023, Accuracy: 3636/5909 (62%), time :148.3850393295288\n",
            "Test set: Average loss: 1.5055, Accuracy: 843/1478 (57%)\n",
            "\n",
            "Train Epoch: 114,Loss: 1.307020, Accuracy: 3657/5909 (62%), time :147.73611402511597\n",
            "Test set: Average loss: 1.4744, Accuracy: 865/1478 (59%)\n",
            "\n",
            "Train Epoch: 115,Loss: 1.316318, Accuracy: 3635/5909 (62%), time :148.33375906944275\n",
            "Test set: Average loss: 1.5684, Accuracy: 838/1478 (57%)\n",
            "\n",
            "Train Epoch: 116,Loss: 1.283266, Accuracy: 3666/5909 (62%), time :148.24247026443481\n",
            "Test set: Average loss: 1.6013, Accuracy: 796/1478 (54%)\n",
            "\n",
            "Train Epoch: 117,Loss: 1.298965, Accuracy: 3693/5909 (62%), time :148.3529851436615\n",
            "Test set: Average loss: 1.4714, Accuracy: 857/1478 (58%)\n",
            "\n",
            "Train Epoch: 118,Loss: 1.272274, Accuracy: 3728/5909 (63%), time :148.2248785495758\n",
            "Test set: Average loss: 1.6362, Accuracy: 824/1478 (56%)\n",
            "\n",
            "Train Epoch: 119,Loss: 1.249437, Accuracy: 3806/5909 (64%), time :158.15371942520142\n",
            "Test set: Average loss: 1.5002, Accuracy: 833/1478 (56%)\n",
            "\n",
            "Train Epoch: 120,Loss: 1.267155, Accuracy: 3764/5909 (64%), time :148.45140385627747\n",
            "Test set: Average loss: 1.4562, Accuracy: 870/1478 (59%)\n",
            "\n",
            "Train Epoch: 121,Loss: 1.270665, Accuracy: 3728/5909 (63%), time :148.4776952266693\n",
            "Test set: Average loss: 1.4797, Accuracy: 883/1478 (60%)\n",
            "\n",
            "Train Epoch: 122,Loss: 1.265224, Accuracy: 3746/5909 (63%), time :148.3788070678711\n",
            "Test set: Average loss: 1.6188, Accuracy: 816/1478 (55%)\n",
            "\n",
            "Train Epoch: 123,Loss: 1.280858, Accuracy: 3723/5909 (63%), time :148.6564130783081\n",
            "Test set: Average loss: 1.5010, Accuracy: 852/1478 (58%)\n",
            "\n",
            "Train Epoch: 124,Loss: 1.259992, Accuracy: 3745/5909 (63%), time :148.4775264263153\n",
            "Test set: Average loss: 1.4971, Accuracy: 873/1478 (59%)\n",
            "\n",
            "Train Epoch: 125,Loss: 1.243473, Accuracy: 3747/5909 (63%), time :149.30914616584778\n",
            "Test set: Average loss: 1.5405, Accuracy: 857/1478 (58%)\n",
            "\n",
            "Train Epoch: 126,Loss: 1.236742, Accuracy: 3762/5909 (64%), time :148.756502866745\n",
            "Test set: Average loss: 1.4991, Accuracy: 853/1478 (58%)\n",
            "\n",
            "Train Epoch: 127,Loss: 1.218029, Accuracy: 3825/5909 (65%), time :148.10246348381042\n",
            "Test set: Average loss: 1.5194, Accuracy: 849/1478 (57%)\n",
            "\n",
            "Train Epoch: 128,Loss: 1.276842, Accuracy: 3709/5909 (63%), time :149.80576348304749\n",
            "Test set: Average loss: 1.5012, Accuracy: 839/1478 (57%)\n",
            "\n",
            "Train Epoch: 129,Loss: 1.240234, Accuracy: 3731/5909 (63%), time :164.15861320495605\n",
            "Test set: Average loss: 1.4651, Accuracy: 860/1478 (58%)\n",
            "\n",
            "Train Epoch: 130,Loss: 1.217514, Accuracy: 3767/5909 (64%), time :148.39307022094727\n",
            "Test set: Average loss: 1.4569, Accuracy: 876/1478 (59%)\n",
            "\n",
            "Train Epoch: 131,Loss: 1.214165, Accuracy: 3838/5909 (65%), time :148.69146823883057\n",
            "Test set: Average loss: 1.4396, Accuracy: 870/1478 (59%)\n",
            "\n",
            "Train Epoch: 132,Loss: 1.204549, Accuracy: 3866/5909 (65%), time :147.67362666130066\n",
            "Test set: Average loss: 1.4413, Accuracy: 898/1478 (61%)\n",
            "\n",
            "Train Epoch: 133,Loss: 1.203900, Accuracy: 3850/5909 (65%), time :147.21645188331604\n",
            "Test set: Average loss: 1.5189, Accuracy: 857/1478 (58%)\n",
            "\n",
            "Train Epoch: 134,Loss: 1.204629, Accuracy: 3830/5909 (65%), time :148.10124230384827\n",
            "Test set: Average loss: 1.4831, Accuracy: 856/1478 (58%)\n",
            "\n",
            "Train Epoch: 135,Loss: 1.183465, Accuracy: 3864/5909 (65%), time :148.27831888198853\n",
            "Test set: Average loss: 1.3516, Accuracy: 904/1478 (61%)\n",
            "\n",
            "Train Epoch: 136,Loss: 1.180642, Accuracy: 3844/5909 (65%), time :148.15549445152283\n",
            "Test set: Average loss: 1.4757, Accuracy: 871/1478 (59%)\n",
            "\n",
            "Train Epoch: 137,Loss: 1.187909, Accuracy: 3846/5909 (65%), time :148.3512532711029\n",
            "Test set: Average loss: 1.5040, Accuracy: 866/1478 (59%)\n",
            "\n",
            "Train Epoch: 138,Loss: 1.180686, Accuracy: 3910/5909 (66%), time :147.80631279945374\n",
            "Test set: Average loss: 1.4926, Accuracy: 864/1478 (58%)\n",
            "\n",
            "Train Epoch: 139,Loss: 1.176786, Accuracy: 3878/5909 (66%), time :158.0917363166809\n",
            "Test set: Average loss: 1.4587, Accuracy: 873/1478 (59%)\n",
            "\n",
            "Train Epoch: 140,Loss: 1.179958, Accuracy: 3875/5909 (66%), time :148.42580437660217\n",
            "Test set: Average loss: 1.4203, Accuracy: 877/1478 (59%)\n",
            "\n",
            "Train Epoch: 141,Loss: 1.187567, Accuracy: 3878/5909 (66%), time :148.22691416740417\n",
            "Test set: Average loss: 1.4205, Accuracy: 885/1478 (60%)\n",
            "\n",
            "Train Epoch: 142,Loss: 1.170377, Accuracy: 3875/5909 (66%), time :148.08414506912231\n",
            "Test set: Average loss: 1.4948, Accuracy: 856/1478 (58%)\n",
            "\n",
            "Train Epoch: 143,Loss: 1.139059, Accuracy: 3961/5909 (67%), time :147.5146791934967\n",
            "Test set: Average loss: 1.4054, Accuracy: 909/1478 (62%)\n",
            "\n",
            "Train Epoch: 144,Loss: 1.145570, Accuracy: 3908/5909 (66%), time :148.46265172958374\n",
            "Test set: Average loss: 1.4561, Accuracy: 883/1478 (60%)\n",
            "\n",
            "Train Epoch: 145,Loss: 1.150326, Accuracy: 3945/5909 (67%), time :149.81984758377075\n",
            "Test set: Average loss: 1.4602, Accuracy: 879/1478 (59%)\n",
            "\n",
            "Train Epoch: 146,Loss: 1.175189, Accuracy: 3943/5909 (67%), time :148.84416508674622\n",
            "Test set: Average loss: 1.4341, Accuracy: 897/1478 (61%)\n",
            "\n",
            "Train Epoch: 147,Loss: 1.140520, Accuracy: 3993/5909 (68%), time :148.96879196166992\n",
            "Test set: Average loss: 1.4217, Accuracy: 884/1478 (60%)\n",
            "\n",
            "Train Epoch: 148,Loss: 1.126753, Accuracy: 4019/5909 (68%), time :149.69095396995544\n",
            "Test set: Average loss: 1.3950, Accuracy: 915/1478 (62%)\n",
            "\n",
            "Train Epoch: 149,Loss: 1.095946, Accuracy: 4007/5909 (68%), time :164.66675519943237\n",
            "Test set: Average loss: 1.3860, Accuracy: 904/1478 (61%)\n",
            "\n",
            "Train Epoch: 150,Loss: 1.113480, Accuracy: 4040/5909 (68%), time :149.71984958648682\n",
            "Test set: Average loss: 1.4448, Accuracy: 889/1478 (60%)\n",
            "\n",
            "Train Epoch: 151,Loss: 1.100793, Accuracy: 4042/5909 (68%), time :150.25377249717712\n",
            "Test set: Average loss: 1.4958, Accuracy: 848/1478 (57%)\n",
            "\n",
            "Train Epoch: 152,Loss: 1.122243, Accuracy: 4016/5909 (68%), time :150.11695408821106\n",
            "Test set: Average loss: 1.4647, Accuracy: 873/1478 (59%)\n",
            "\n",
            "Train Epoch: 153,Loss: 1.122943, Accuracy: 3963/5909 (67%), time :150.41043376922607\n",
            "Test set: Average loss: 1.3741, Accuracy: 924/1478 (63%)\n",
            "\n",
            "Train Epoch: 154,Loss: 1.108796, Accuracy: 4020/5909 (68%), time :150.59618639945984\n",
            "Test set: Average loss: 1.4859, Accuracy: 863/1478 (58%)\n",
            "\n",
            "Train Epoch: 155,Loss: 1.117639, Accuracy: 3990/5909 (68%), time :150.34603595733643\n",
            "Test set: Average loss: 1.3248, Accuracy: 936/1478 (63%)\n",
            "\n",
            "Train Epoch: 156,Loss: 1.099378, Accuracy: 4021/5909 (68%), time :150.82190370559692\n",
            "Test set: Average loss: 1.4013, Accuracy: 892/1478 (60%)\n",
            "\n",
            "Train Epoch: 157,Loss: 1.094012, Accuracy: 4048/5909 (69%), time :150.10592460632324\n",
            "Test set: Average loss: 1.3612, Accuracy: 919/1478 (62%)\n",
            "\n",
            "Train Epoch: 158,Loss: 1.078609, Accuracy: 4097/5909 (69%), time :149.8194122314453\n",
            "Test set: Average loss: 1.4763, Accuracy: 866/1478 (59%)\n",
            "\n",
            "Train Epoch: 159,Loss: 1.065618, Accuracy: 4092/5909 (69%), time :165.2277431488037\n",
            "Test set: Average loss: 1.4760, Accuracy: 884/1478 (60%)\n",
            "\n",
            "Train Epoch: 160,Loss: 1.061609, Accuracy: 4071/5909 (69%), time :149.51150488853455\n",
            "Test set: Average loss: 1.3311, Accuracy: 922/1478 (62%)\n",
            "\n",
            "Train Epoch: 161,Loss: 1.093603, Accuracy: 4018/5909 (68%), time :146.86309027671814\n",
            "Test set: Average loss: 1.6020, Accuracy: 835/1478 (56%)\n",
            "\n",
            "Train Epoch: 162,Loss: 1.086470, Accuracy: 4047/5909 (68%), time :146.56469130516052\n",
            "Test set: Average loss: 1.4827, Accuracy: 877/1478 (59%)\n",
            "\n",
            "Train Epoch: 163,Loss: 1.064436, Accuracy: 4097/5909 (69%), time :146.44441556930542\n",
            "Test set: Average loss: 1.2990, Accuracy: 971/1478 (66%)\n",
            "\n",
            "Train Epoch: 164,Loss: 1.076981, Accuracy: 4089/5909 (69%), time :148.15254545211792\n",
            "Test set: Average loss: 1.3839, Accuracy: 932/1478 (63%)\n",
            "\n",
            "Train Epoch: 165,Loss: 1.053665, Accuracy: 4073/5909 (69%), time :148.36948895454407\n",
            "Test set: Average loss: 1.3290, Accuracy: 938/1478 (63%)\n",
            "\n",
            "Train Epoch: 166,Loss: 1.062291, Accuracy: 4119/5909 (70%), time :148.32020592689514\n",
            "Test set: Average loss: 1.3480, Accuracy: 917/1478 (62%)\n",
            "\n",
            "Train Epoch: 167,Loss: 1.065731, Accuracy: 4066/5909 (69%), time :148.52236890792847\n",
            "Test set: Average loss: 1.2901, Accuracy: 933/1478 (63%)\n",
            "\n",
            "Train Epoch: 168,Loss: 1.036727, Accuracy: 4130/5909 (70%), time :147.840473651886\n",
            "Test set: Average loss: 1.3298, Accuracy: 945/1478 (64%)\n",
            "\n",
            "Train Epoch: 169,Loss: 1.047878, Accuracy: 4131/5909 (70%), time :160.10880994796753\n",
            "Test set: Average loss: 1.2809, Accuracy: 940/1478 (64%)\n",
            "\n",
            "Train Epoch: 170,Loss: 1.021758, Accuracy: 4187/5909 (71%), time :148.09279561042786\n",
            "Test set: Average loss: 1.3340, Accuracy: 937/1478 (63%)\n",
            "\n",
            "Train Epoch: 171,Loss: 1.069405, Accuracy: 4080/5909 (69%), time :147.06795930862427\n",
            "Test set: Average loss: 1.3137, Accuracy: 961/1478 (65%)\n",
            "\n",
            "Train Epoch: 172,Loss: 1.014772, Accuracy: 4160/5909 (70%), time :146.8495101928711\n",
            "Test set: Average loss: 1.2998, Accuracy: 953/1478 (64%)\n",
            "\n",
            "Train Epoch: 173,Loss: 1.019561, Accuracy: 4207/5909 (71%), time :147.14862322807312\n",
            "Test set: Average loss: 1.3798, Accuracy: 919/1478 (62%)\n",
            "\n",
            "Train Epoch: 174,Loss: 1.023699, Accuracy: 4139/5909 (70%), time :147.82195830345154\n",
            "Test set: Average loss: 1.3154, Accuracy: 948/1478 (64%)\n",
            "\n",
            "Train Epoch: 175,Loss: 1.033315, Accuracy: 4143/5909 (70%), time :147.87333941459656\n",
            "Test set: Average loss: 1.3752, Accuracy: 938/1478 (63%)\n",
            "\n",
            "Train Epoch: 176,Loss: 0.994585, Accuracy: 4256/5909 (72%), time :148.33665561676025\n",
            "Test set: Average loss: 1.2842, Accuracy: 979/1478 (66%)\n",
            "\n",
            "Train Epoch: 177,Loss: 0.994440, Accuracy: 4249/5909 (72%), time :148.1257607936859\n",
            "Test set: Average loss: 1.3714, Accuracy: 923/1478 (62%)\n",
            "\n",
            "Train Epoch: 178,Loss: 1.023680, Accuracy: 4185/5909 (71%), time :147.8650574684143\n",
            "Test set: Average loss: 1.4276, Accuracy: 902/1478 (61%)\n",
            "\n",
            "Train Epoch: 179,Loss: 0.995138, Accuracy: 4229/5909 (72%), time :160.6697759628296\n",
            "Test set: Average loss: 1.3193, Accuracy: 956/1478 (65%)\n",
            "\n",
            "Train Epoch: 180,Loss: 0.997106, Accuracy: 4248/5909 (72%), time :147.73693561553955\n",
            "Test set: Average loss: 1.2804, Accuracy: 961/1478 (65%)\n",
            "\n",
            "Train Epoch: 181,Loss: 1.007044, Accuracy: 4207/5909 (71%), time :147.66364359855652\n",
            "Test set: Average loss: 1.2470, Accuracy: 967/1478 (65%)\n",
            "\n",
            "Train Epoch: 182,Loss: 0.965273, Accuracy: 4255/5909 (72%), time :147.71542191505432\n",
            "Test set: Average loss: 1.3339, Accuracy: 956/1478 (65%)\n",
            "\n",
            "Train Epoch: 183,Loss: 1.003096, Accuracy: 4164/5909 (70%), time :148.13559746742249\n",
            "Test set: Average loss: 1.3872, Accuracy: 926/1478 (63%)\n",
            "\n",
            "Train Epoch: 184,Loss: 0.981861, Accuracy: 4261/5909 (72%), time :148.23224329948425\n",
            "Test set: Average loss: 1.4105, Accuracy: 926/1478 (63%)\n",
            "\n",
            "Train Epoch: 185,Loss: 0.976710, Accuracy: 4261/5909 (72%), time :148.70505547523499\n",
            "Test set: Average loss: 1.3649, Accuracy: 945/1478 (64%)\n",
            "\n",
            "Train Epoch: 186,Loss: 0.974942, Accuracy: 4312/5909 (73%), time :149.5760350227356\n",
            "Test set: Average loss: 1.4205, Accuracy: 917/1478 (62%)\n",
            "\n",
            "Train Epoch: 187,Loss: 0.951443, Accuracy: 4313/5909 (73%), time :148.94599556922913\n",
            "Test set: Average loss: 1.2635, Accuracy: 968/1478 (65%)\n",
            "\n",
            "Train Epoch: 188,Loss: 0.948819, Accuracy: 4316/5909 (73%), time :149.25473928451538\n",
            "Test set: Average loss: 1.3399, Accuracy: 922/1478 (62%)\n",
            "\n",
            "Train Epoch: 189,Loss: 0.958227, Accuracy: 4260/5909 (72%), time :164.00373435020447\n",
            "Test set: Average loss: 1.2701, Accuracy: 972/1478 (66%)\n",
            "\n",
            "Train Epoch: 190,Loss: 0.957978, Accuracy: 4290/5909 (73%), time :149.09613966941833\n",
            "Test set: Average loss: 1.3364, Accuracy: 939/1478 (64%)\n",
            "\n",
            "Train Epoch: 191,Loss: 0.960541, Accuracy: 4276/5909 (72%), time :148.32848834991455\n",
            "Test set: Average loss: 1.2580, Accuracy: 957/1478 (65%)\n",
            "\n",
            "Train Epoch: 192,Loss: 0.949419, Accuracy: 4364/5909 (74%), time :148.92090249061584\n",
            "Test set: Average loss: 1.4840, Accuracy: 896/1478 (61%)\n",
            "\n",
            "Train Epoch: 193,Loss: 0.953763, Accuracy: 4306/5909 (73%), time :149.0444736480713\n",
            "Test set: Average loss: 1.2888, Accuracy: 960/1478 (65%)\n",
            "\n",
            "Train Epoch: 194,Loss: 0.958761, Accuracy: 4319/5909 (73%), time :148.9188916683197\n",
            "Test set: Average loss: 1.3204, Accuracy: 934/1478 (63%)\n",
            "\n",
            "Train Epoch: 195,Loss: 0.968257, Accuracy: 4268/5909 (72%), time :148.93956446647644\n",
            "Test set: Average loss: 1.3275, Accuracy: 945/1478 (64%)\n",
            "\n",
            "Train Epoch: 196,Loss: 0.927176, Accuracy: 4355/5909 (74%), time :148.66264867782593\n",
            "Test set: Average loss: 1.3413, Accuracy: 945/1478 (64%)\n",
            "\n",
            "Train Epoch: 197,Loss: 0.928832, Accuracy: 4361/5909 (74%), time :149.0627624988556\n",
            "Test set: Average loss: 1.2718, Accuracy: 955/1478 (65%)\n",
            "\n",
            "Train Epoch: 198,Loss: 0.942488, Accuracy: 4310/5909 (73%), time :150.17136907577515\n",
            "Test set: Average loss: 1.3540, Accuracy: 946/1478 (64%)\n",
            "\n",
            "Train Epoch: 199,Loss: 0.946391, Accuracy: 4308/5909 (73%), time :165.95506763458252\n",
            "Test set: Average loss: 1.2918, Accuracy: 967/1478 (65%)\n",
            "\n",
            "Train Epoch: 200,Loss: 0.916274, Accuracy: 4366/5909 (74%), time :149.2543923854828\n",
            "Test set: Average loss: 1.2980, Accuracy: 964/1478 (65%)\n",
            "\n",
            "Train Epoch: 201,Loss: 0.929928, Accuracy: 4393/5909 (74%), time :150.0531404018402\n",
            "Test set: Average loss: 1.3353, Accuracy: 932/1478 (63%)\n",
            "\n",
            "Train Epoch: 202,Loss: 0.935679, Accuracy: 4322/5909 (73%), time :148.68797969818115\n",
            "Test set: Average loss: 1.2714, Accuracy: 985/1478 (67%)\n",
            "\n",
            "Train Epoch: 203,Loss: 0.924394, Accuracy: 4344/5909 (74%), time :148.76674675941467\n",
            "Test set: Average loss: 1.2688, Accuracy: 967/1478 (65%)\n",
            "\n",
            "Train Epoch: 204,Loss: 0.919410, Accuracy: 4389/5909 (74%), time :148.4057068824768\n",
            "Test set: Average loss: 1.3420, Accuracy: 939/1478 (64%)\n",
            "\n",
            "Train Epoch: 205,Loss: 0.921074, Accuracy: 4363/5909 (74%), time :148.47331047058105\n",
            "Test set: Average loss: 1.2761, Accuracy: 955/1478 (65%)\n",
            "\n",
            "Train Epoch: 206,Loss: 0.905563, Accuracy: 4428/5909 (75%), time :147.98512387275696\n",
            "Test set: Average loss: 1.2183, Accuracy: 987/1478 (67%)\n",
            "\n",
            "Train Epoch: 207,Loss: 0.907209, Accuracy: 4396/5909 (74%), time :147.10444521903992\n",
            "Test set: Average loss: 1.3275, Accuracy: 959/1478 (65%)\n",
            "\n",
            "Train Epoch: 208,Loss: 0.908119, Accuracy: 4412/5909 (75%), time :147.26819849014282\n",
            "Test set: Average loss: 1.2626, Accuracy: 973/1478 (66%)\n",
            "\n",
            "Train Epoch: 209,Loss: 0.919829, Accuracy: 4366/5909 (74%), time :162.0071132183075\n",
            "Test set: Average loss: 1.2243, Accuracy: 997/1478 (67%)\n",
            "\n",
            "Train Epoch: 210,Loss: 0.910573, Accuracy: 4392/5909 (74%), time :148.30725026130676\n",
            "Test set: Average loss: 1.3617, Accuracy: 939/1478 (64%)\n",
            "\n",
            "Train Epoch: 211,Loss: 0.894121, Accuracy: 4444/5909 (75%), time :147.6099350452423\n",
            "Test set: Average loss: 1.2758, Accuracy: 953/1478 (64%)\n",
            "\n",
            "Train Epoch: 212,Loss: 0.880385, Accuracy: 4447/5909 (75%), time :147.7463562488556\n",
            "Test set: Average loss: 1.3474, Accuracy: 965/1478 (65%)\n",
            "\n",
            "Train Epoch: 213,Loss: 0.893495, Accuracy: 4421/5909 (75%), time :147.4343180656433\n",
            "Test set: Average loss: 1.3148, Accuracy: 960/1478 (65%)\n",
            "\n",
            "Train Epoch: 214,Loss: 0.885506, Accuracy: 4443/5909 (75%), time :147.2025830745697\n",
            "Test set: Average loss: 1.2680, Accuracy: 975/1478 (66%)\n",
            "\n",
            "Train Epoch: 215,Loss: 0.881878, Accuracy: 4515/5909 (76%), time :146.47321271896362\n",
            "Test set: Average loss: 1.3254, Accuracy: 965/1478 (65%)\n",
            "\n",
            "Train Epoch: 216,Loss: 0.872688, Accuracy: 4441/5909 (75%), time :147.456609249115\n",
            "Test set: Average loss: 1.3400, Accuracy: 977/1478 (66%)\n",
            "\n",
            "Train Epoch: 217,Loss: 0.876632, Accuracy: 4442/5909 (75%), time :147.79894161224365\n",
            "Test set: Average loss: 1.2426, Accuracy: 994/1478 (67%)\n",
            "\n",
            "Train Epoch: 218,Loss: 0.899412, Accuracy: 4384/5909 (74%), time :147.20383763313293\n",
            "Test set: Average loss: 1.3305, Accuracy: 962/1478 (65%)\n",
            "\n",
            "Train Epoch: 219,Loss: 0.858083, Accuracy: 4503/5909 (76%), time :159.52928042411804\n",
            "Test set: Average loss: 1.3417, Accuracy: 925/1478 (63%)\n",
            "\n",
            "Train Epoch: 220,Loss: 0.886335, Accuracy: 4418/5909 (75%), time :145.8294060230255\n",
            "Test set: Average loss: 1.2885, Accuracy: 969/1478 (66%)\n",
            "\n",
            "Train Epoch: 221,Loss: 0.910823, Accuracy: 4368/5909 (74%), time :146.3009967803955\n",
            "Test set: Average loss: 1.2917, Accuracy: 973/1478 (66%)\n",
            "\n",
            "Train Epoch: 222,Loss: 0.867328, Accuracy: 4441/5909 (75%), time :146.02201747894287\n",
            "Test set: Average loss: 1.3350, Accuracy: 949/1478 (64%)\n",
            "\n",
            "Train Epoch: 223,Loss: 0.877750, Accuracy: 4473/5909 (76%), time :147.8708038330078\n",
            "Test set: Average loss: 1.2295, Accuracy: 985/1478 (67%)\n",
            "\n",
            "Train Epoch: 224,Loss: 0.863554, Accuracy: 4468/5909 (76%), time :146.7882513999939\n",
            "Test set: Average loss: 1.3861, Accuracy: 947/1478 (64%)\n",
            "\n",
            "Train Epoch: 225,Loss: 0.857459, Accuracy: 4469/5909 (76%), time :146.76393508911133\n",
            "Test set: Average loss: 1.3203, Accuracy: 958/1478 (65%)\n",
            "\n",
            "Train Epoch: 226,Loss: 0.871813, Accuracy: 4463/5909 (76%), time :146.74691104888916\n",
            "Test set: Average loss: 1.3399, Accuracy: 934/1478 (63%)\n",
            "\n",
            "Train Epoch: 227,Loss: 0.836878, Accuracy: 4534/5909 (77%), time :145.47130680084229\n",
            "Test set: Average loss: 1.3493, Accuracy: 916/1478 (62%)\n",
            "\n",
            "Train Epoch: 228,Loss: 0.869669, Accuracy: 4483/5909 (76%), time :145.87268471717834\n",
            "Test set: Average loss: 1.3294, Accuracy: 947/1478 (64%)\n",
            "\n",
            "Train Epoch: 229,Loss: 0.844935, Accuracy: 4542/5909 (77%), time :160.05698657035828\n",
            "Test set: Average loss: 1.2017, Accuracy: 982/1478 (66%)\n",
            "\n",
            "Train Epoch: 230,Loss: 0.853119, Accuracy: 4501/5909 (76%), time :146.23634576797485\n",
            "Test set: Average loss: 1.2018, Accuracy: 1014/1478 (69%)\n",
            "\n",
            "Train Epoch: 231,Loss: 0.843194, Accuracy: 4519/5909 (76%), time :145.87809920310974\n",
            "Test set: Average loss: 1.2198, Accuracy: 1001/1478 (68%)\n",
            "\n",
            "Train Epoch: 232,Loss: 0.862452, Accuracy: 4486/5909 (76%), time :146.12287712097168\n",
            "Test set: Average loss: 1.3139, Accuracy: 976/1478 (66%)\n",
            "\n",
            "Train Epoch: 233,Loss: 0.788193, Accuracy: 4636/5909 (78%), time :146.88143110275269\n",
            "Test set: Average loss: 1.2246, Accuracy: 998/1478 (68%)\n",
            "\n",
            "Train Epoch: 234,Loss: 0.829642, Accuracy: 4545/5909 (77%), time :146.65506672859192\n",
            "Test set: Average loss: 1.2525, Accuracy: 988/1478 (67%)\n",
            "\n",
            "Train Epoch: 235,Loss: 0.811219, Accuracy: 4550/5909 (77%), time :146.07023310661316\n",
            "Test set: Average loss: 1.2494, Accuracy: 990/1478 (67%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV1aRkGhqcKi"
      },
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('u-net Model Accuracy', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Accuaracy', fontsize = 15)\n",
        "plt.ylim(0,2)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgnsp5veqXsn"
      },
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(loss_val)\n",
        "plt.title('u-net Model Loss', fontsize = 15)\n",
        "plt.xlabel('Epoch', fontsize = 15)\n",
        "plt.ylabel('Loss', fontsize = 15)\n",
        "plt.ylim(0,1.3)\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYpz7eNern60"
      },
      "source": [
        "path = '/content/drive/MyDrive/oxford_pet/seventhh_u-net_clf_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYxSh9D57XFU"
      },
      "source": [
        "pred = F.softmax(masks_pred,dim = 1)\n",
        "prediction = torch.argmax(pred,dim = 1)\n",
        "prediction[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQKp83CTqV2B"
      },
      "source": [
        "torch.save(net.state_dict(),path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRP8RWN_rf1t"
      },
      "source": [
        "plt.imshow(inputs[1].permute(1,2,0).cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov1jzm9aCp1M"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4z2JNfP787-"
      },
      "source": [
        "plt.imshow(masks[1].cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOtetGLZ8T7u"
      },
      "source": [
        "plt.imshow(prediction[1].cpu().data.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DacbuUZ08a8K"
      },
      "source": [
        "mIoU(masks_pred[0],labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5bG4FW_nt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
